{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernel_info": {
      "name": "u4-s1-nlp"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "nteract": {
      "version": "0.15.0"
    },
    "toc-autonumbering": false,
    "colab": {
      "name": "LS_DS_415_Sprint_Challenge_1_AG.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nicholashagemann/DS-Assignment-Submission-Practice-Repository/blob/master/LS_DS_415_Sprint_Challenge_1_AG.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AgUcZubyaGHI"
      },
      "source": [
        "# Sprint Challenge\n",
        "## *Data Science Unit 4 Sprint 1*\n",
        "\n",
        "After a week of Natural Language Processing, you've learned some cool new stuff: how to process text, how turn text into vectors, and how to model topics from documents. Apply your newly acquired skills to one of the most famous NLP datasets out there: [Yelp](https://www.yelp.com/dataset). As part of the job selection process, some of my friends have been asked to create analysis of this dataset, so I want to empower you to have a head start.  \n",
        "\n",
        "The real dataset is massive (almost 8 gigs uncompressed). I've sampled the data for you to something more manageable for the Sprint Challenge. You can analyze the full dataset as a stretch goal or after the sprint challenge. As you work on the challenge, I suggest adding notes about your findings and things you want to analyze in the future.\n",
        "\n",
        "## Challenge Objectives\n",
        "Successfully complete all these objectives to earn full credit. \n",
        "\n",
        "**Successful completion is defined as passing all the unit tests in each objective.**  \n",
        "\n",
        "Each unit test that you pass is 1 point. \n",
        "\n",
        "There are 5 total possible points in this sprint challenge. \n",
        "\n",
        "\n",
        "There are more details on each objective further down in the notebook.*\n",
        "* <a href=\"#p1\">Part 1</a>: Write a function to tokenize the yelp reviews\n",
        "* <a href=\"#p2\">Part 2</a>: Create a vector representation of those tokens\n",
        "* <a href=\"#p3\">Part 3</a>: Use your tokens in a classification model on yelp rating\n",
        "* <a href=\"#p4\">Part 4</a>: Estimate & Interpret a topic model of the Yelp reviews\n",
        "\n",
        "____\n",
        "\n",
        "# Before you submit your notebook you must first\n",
        "\n",
        "1) Restart your notebook's Kernel\n",
        "\n",
        "2) Run all cells sequentially, from top to bottom, so that cell numbers are sequential numbers (i.e. 1,2,3,4,5...)\n",
        "- Easiest way to do this is to click on the **Cell** tab at the top of your notebook and select **Run All** from the drop down menu. \n",
        "\n",
        "3) Comment out the cell that generates a pyLDAvis visual in objective 4 (see instructions in that section). \n",
        "____"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x_Nqeah9aGHN"
      },
      "source": [
        "\n",
        "\n",
        "### Import Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PBINGBkZaqog",
        "outputId": "a6c5d7bb-7f34-4b62-bf5c-693a5d351fb5"
      },
      "source": [
        "# install spacy\n",
        "!python -m spacy download en_core_web_md\n",
        "# remember to restart the runtime"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting en_core_web_md==2.2.5\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_md-2.2.5/en_core_web_md-2.2.5.tar.gz (96.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 96.4 MB 1.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.7/dist-packages (from en_core_web_md==2.2.5) (2.2.4)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (7.4.0)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (1.0.0)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (3.0.5)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (1.0.5)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (1.1.3)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (4.62.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (2.23.0)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (2.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (1.0.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (57.4.0)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (1.19.5)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (0.4.1)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (0.8.2)\n",
            "Requirement already satisfied: importlib-metadata>=0.20 in /usr/local/lib/python3.7/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_md==2.2.5) (4.6.4)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_md==2.2.5) (3.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_md==2.2.5) (3.7.4.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_md==2.2.5) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_md==2.2.5) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_md==2.2.5) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_md==2.2.5) (2021.5.30)\n",
            "Building wheels for collected packages: en-core-web-md\n",
            "  Building wheel for en-core-web-md (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for en-core-web-md: filename=en_core_web_md-2.2.5-py3-none-any.whl size=98051302 sha256=f851db51b348f5d285ceb114862fff137abac64af69ff31a6a3589422ea5f29e\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-hqz9uaa5/wheels/69/c5/b8/4f1c029d89238734311b3269762ab2ee325a42da2ce8edb997\n",
            "Successfully built en-core-web-md\n",
            "Installing collected packages: en-core-web-md\n",
            "Successfully installed en-core-web-md-2.2.5\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('en_core_web_md')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D8WRyMPjauql",
        "outputId": "52838af7-076d-4b62-bd54-97ae720efa8a"
      },
      "source": [
        "# install same requirements we've been using throughout the week\n",
        "!wget https://raw.githubusercontent.com/LambdaSchool/DS-Unit-4-Sprint-1-NLP/main/requirements.txt\n",
        "!pip install -r requirements.txt"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      Successfully uninstalled spacy-2.2.4\n",
            "  Attempting uninstall: seaborn\n",
            "    Found existing installation: seaborn 0.11.1\n",
            "    Uninstalling seaborn-0.11.1:\n",
            "      Successfully uninstalled seaborn-0.11.1\n",
            "  Attempting uninstall: scikit-learn\n",
            "    Found existing installation: scikit-learn 0.22.2.post1\n",
            "    Uninstalling scikit-learn-0.22.2.post1:\n",
            "      Successfully uninstalled scikit-learn-0.22.2.post1\n",
            "  Attempting uninstall: gensim\n",
            "    Found existing installation: gensim 3.6.0\n",
            "    Uninstalling gensim-3.6.0:\n",
            "      Successfully uninstalled gensim-3.6.0\n",
            "Successfully installed funcy-1.16 gensim-3.8.1 pandarallel-1.5.2 pyLDAvis-2.1.2 scikit-learn-0.22.2 seaborn-0.9.0 spacy-2.2.3 squarify-0.4.3 thinc-7.3.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X4ZucOhsa_lo",
        "outputId": "66e96b43-f5dd-44db-f0be-7ad0e86f74ad"
      },
      "source": [
        "# install imports\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from collections import Counter\n",
        "import re\n",
        "import squarify\n",
        "\n",
        "import spacy\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "from sklearn.decomposition import PCA"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HY3wSVdgcaHZ",
        "outputId": "f2268c0f-7cfc-40bb-bedd-f4dc51e2140b"
      },
      "source": [
        "! git clone https://github.com/LambdaSchool/data-science-practice-datasets.git"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'data-science-practice-datasets'...\n",
            "remote: Enumerating objects: 755, done.\u001b[K\n",
            "remote: Counting objects: 100% (146/146), done.\u001b[K\n",
            "remote: Compressing objects: 100% (133/133), done.\u001b[K\n",
            "remote: Total 755 (delta 61), reused 10 (delta 2), pack-reused 609\u001b[K\n",
            "Receiving objects: 100% (755/755), 83.04 MiB | 20.55 MiB/s, done.\n",
            "Resolving deltas: 100% (339/339), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "7bec125eb29f89460cf0c19ba9aa9a2f",
          "grade": false,
          "grade_id": "cell-395851cd95d17235",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "J97kpHJ7aGHO"
      },
      "source": [
        "# Load reviews from URL\n",
        "data_url = 'https://raw.githubusercontent.com/LambdaSchool/data-science-practice-datasets/main/unit_4/unit1_nlp/review_sample.json'\n",
        "\n",
        "# Import data into a DataFrame named df\n",
        "# YOUR CODE HERE\n",
        "df = pd.read_json(data_url, lines=True)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        },
        "id": "bM0pHjIOc8L3",
        "outputId": "bb67d88d-0909-4725-dd9e-64a8ac05a5c1"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>business_id</th>\n",
              "      <th>cool</th>\n",
              "      <th>date</th>\n",
              "      <th>funny</th>\n",
              "      <th>review_id</th>\n",
              "      <th>stars</th>\n",
              "      <th>text</th>\n",
              "      <th>useful</th>\n",
              "      <th>user_id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>nDuEqIyRc8YKS1q1fX0CZg</td>\n",
              "      <td>1</td>\n",
              "      <td>2015-03-31 16:50:30</td>\n",
              "      <td>0</td>\n",
              "      <td>eZs2tpEJtXPwawvHnHZIgQ</td>\n",
              "      <td>1</td>\n",
              "      <td>BEWARE!!! FAKE, FAKE, FAKE....We also own a sm...</td>\n",
              "      <td>10</td>\n",
              "      <td>n1LM36qNg4rqGXIcvVXv8w</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>eMYeEapscbKNqUDCx705hg</td>\n",
              "      <td>0</td>\n",
              "      <td>2015-12-16 05:31:03</td>\n",
              "      <td>0</td>\n",
              "      <td>DoQDWJsNbU0KL1O29l_Xug</td>\n",
              "      <td>4</td>\n",
              "      <td>Came here for lunch Togo. Service was quick. S...</td>\n",
              "      <td>0</td>\n",
              "      <td>5CgjjDAic2-FAvCtiHpytA</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>6Q7-wkCPc1KF75jZLOTcMw</td>\n",
              "      <td>1</td>\n",
              "      <td>2010-06-20 19:14:48</td>\n",
              "      <td>1</td>\n",
              "      <td>DDOdGU7zh56yQHmUnL1idQ</td>\n",
              "      <td>3</td>\n",
              "      <td>I've been to Vegas dozens of times and had nev...</td>\n",
              "      <td>2</td>\n",
              "      <td>BdV-cf3LScmb8kZ7iiBcMA</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>k3zrItO4l9hwfLRwHBDc9w</td>\n",
              "      <td>3</td>\n",
              "      <td>2010-07-13 00:33:45</td>\n",
              "      <td>4</td>\n",
              "      <td>LfTMUWnfGFMOfOIyJcwLVA</td>\n",
              "      <td>1</td>\n",
              "      <td>We went here on a night where they closed off ...</td>\n",
              "      <td>5</td>\n",
              "      <td>cZZnBqh4gAEy4CdNvJailQ</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>6hpfRwGlOzbNv7k5eP9rsQ</td>\n",
              "      <td>1</td>\n",
              "      <td>2018-06-30 02:30:01</td>\n",
              "      <td>0</td>\n",
              "      <td>zJSUdI7bJ8PNJAg4lnl_Gg</td>\n",
              "      <td>4</td>\n",
              "      <td>3.5 to 4 stars\\n\\nNot bad for the price, $12.9...</td>\n",
              "      <td>5</td>\n",
              "      <td>n9QO4ClYAS7h9fpQwa5bhA</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              business_id  cool  ... useful                 user_id\n",
              "0  nDuEqIyRc8YKS1q1fX0CZg     1  ...     10  n1LM36qNg4rqGXIcvVXv8w\n",
              "1  eMYeEapscbKNqUDCx705hg     0  ...      0  5CgjjDAic2-FAvCtiHpytA\n",
              "2  6Q7-wkCPc1KF75jZLOTcMw     1  ...      2  BdV-cf3LScmb8kZ7iiBcMA\n",
              "3  k3zrItO4l9hwfLRwHBDc9w     3  ...      5  cZZnBqh4gAEy4CdNvJailQ\n",
              "4  6hpfRwGlOzbNv7k5eP9rsQ     1  ...      5  n9QO4ClYAS7h9fpQwa5bhA\n",
              "\n",
              "[5 rows x 9 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "356579363f311da83f4ef7abaf3c9212",
          "grade": true,
          "grade_id": "cell-cb5006475e42b8f9",
          "locked": true,
          "points": 1,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "ToHgtyCfaGHQ"
      },
      "source": [
        "# Visible Testing\n",
        "assert isinstance(df, pd.DataFrame), 'df is not a DataFrame. Did you import the data into df?'\n",
        "assert df.shape[0] == 10000, 'DataFrame df has the wrong number of rows.'"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xh6cv8NMaGHR"
      },
      "source": [
        "## Part 1: Tokenize Function\n",
        "<a id=\"#p1\"></a>\n",
        "\n",
        "Complete the function `tokenize`. Your function should\n",
        "- accept one document at a time\n",
        "- return a list of tokens\n",
        "\n",
        "You are free to use any method you have learned this week."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B9lBCDH3aGHS"
      },
      "source": [
        "# Optional: Consider using spaCy in your function. The spaCy library can be imported by running this cell.\n",
        "# A pre-trained model (en_core_web_sm) has been made available to you in the CodeGrade container.\n",
        "# If you DON'T need use the en_core_web_sm model, you can comment it out below.\n",
        "import spacy\n",
        "nlp = spacy.load('en_core_web_sm')"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "4837ed2a1cc13057ba40203859d46ff6",
          "grade": false,
          "grade_id": "cell-3d570d5a1cd6cb64",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "8hv_EEOwaGHT"
      },
      "source": [
        "def tokenize(text):\n",
        "  '''Takes text, cleans it of everything except letters, then returns lemmas of every word,\n",
        "  excluding stop words, as tokens'''\n",
        "  text = re.sub(r'[^a-zA-Z\\s]', ' ', text)\n",
        "  text = re.sub(r'\\s+', ' ', text)\n",
        "  tokens = nlp(text)\n",
        "\n",
        "  return [token.lemma_.lower().strip() for token in tokens if (token.is_stop != True) and (token.is_punct != True)]"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "2181ca9d36070260b1f75dcfd9e58965",
          "grade": true,
          "grade_id": "cell-02da164f6fbe730a",
          "locked": true,
          "points": 1,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "kgSvlOf2aGHT"
      },
      "source": [
        "'''Testing'''\n",
        "assert isinstance(tokenize(df.sample(n=1)[\"text\"].iloc[0]), list), \"Make sure your tokenizer function accepts a single document and returns a list of tokens!\""
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 484
        },
        "id": "I5jf1_k8hjJC",
        "outputId": "b63fa898-26c6-403c-a1c2-5d77cee144b2"
      },
      "source": [
        "# creating our spacy tokens column\n",
        "df['spacy_tokens'] = df['text'].apply(lambda x: tokenize(x))\n",
        "df.head()"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>business_id</th>\n",
              "      <th>cool</th>\n",
              "      <th>date</th>\n",
              "      <th>funny</th>\n",
              "      <th>review_id</th>\n",
              "      <th>stars</th>\n",
              "      <th>text</th>\n",
              "      <th>useful</th>\n",
              "      <th>user_id</th>\n",
              "      <th>spacy_tokens</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>nDuEqIyRc8YKS1q1fX0CZg</td>\n",
              "      <td>1</td>\n",
              "      <td>2015-03-31 16:50:30</td>\n",
              "      <td>0</td>\n",
              "      <td>eZs2tpEJtXPwawvHnHZIgQ</td>\n",
              "      <td>1</td>\n",
              "      <td>BEWARE!!! FAKE, FAKE, FAKE....We also own a sm...</td>\n",
              "      <td>10</td>\n",
              "      <td>n1LM36qNg4rqGXIcvVXv8w</td>\n",
              "      <td>[beware, fake, fake, fake, small, business, lo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>eMYeEapscbKNqUDCx705hg</td>\n",
              "      <td>0</td>\n",
              "      <td>2015-12-16 05:31:03</td>\n",
              "      <td>0</td>\n",
              "      <td>DoQDWJsNbU0KL1O29l_Xug</td>\n",
              "      <td>4</td>\n",
              "      <td>Came here for lunch Togo. Service was quick. S...</td>\n",
              "      <td>0</td>\n",
              "      <td>5CgjjDAic2-FAvCtiHpytA</td>\n",
              "      <td>[come, lunch, togo, service, quick, staff, fri...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>6Q7-wkCPc1KF75jZLOTcMw</td>\n",
              "      <td>1</td>\n",
              "      <td>2010-06-20 19:14:48</td>\n",
              "      <td>1</td>\n",
              "      <td>DDOdGU7zh56yQHmUnL1idQ</td>\n",
              "      <td>3</td>\n",
              "      <td>I've been to Vegas dozens of times and had nev...</td>\n",
              "      <td>2</td>\n",
              "      <td>BdV-cf3LScmb8kZ7iiBcMA</td>\n",
              "      <td>[ve, vegas, dozen, time, step, foot, circus, c...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>k3zrItO4l9hwfLRwHBDc9w</td>\n",
              "      <td>3</td>\n",
              "      <td>2010-07-13 00:33:45</td>\n",
              "      <td>4</td>\n",
              "      <td>LfTMUWnfGFMOfOIyJcwLVA</td>\n",
              "      <td>1</td>\n",
              "      <td>We went here on a night where they closed off ...</td>\n",
              "      <td>5</td>\n",
              "      <td>cZZnBqh4gAEy4CdNvJailQ</td>\n",
              "      <td>[go, night, close, street, party, good, actual...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>6hpfRwGlOzbNv7k5eP9rsQ</td>\n",
              "      <td>1</td>\n",
              "      <td>2018-06-30 02:30:01</td>\n",
              "      <td>0</td>\n",
              "      <td>zJSUdI7bJ8PNJAg4lnl_Gg</td>\n",
              "      <td>4</td>\n",
              "      <td>3.5 to 4 stars\\n\\nNot bad for the price, $12.9...</td>\n",
              "      <td>5</td>\n",
              "      <td>n9QO4ClYAS7h9fpQwa5bhA</td>\n",
              "      <td>[, star, bad, price, lunch, senior, pay, eat, ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              business_id  ...                                       spacy_tokens\n",
              "0  nDuEqIyRc8YKS1q1fX0CZg  ...  [beware, fake, fake, fake, small, business, lo...\n",
              "1  eMYeEapscbKNqUDCx705hg  ...  [come, lunch, togo, service, quick, staff, fri...\n",
              "2  6Q7-wkCPc1KF75jZLOTcMw  ...  [ve, vegas, dozen, time, step, foot, circus, c...\n",
              "3  k3zrItO4l9hwfLRwHBDc9w  ...  [go, night, close, street, party, good, actual...\n",
              "4  6hpfRwGlOzbNv7k5eP9rsQ  ...  [, star, bad, price, lunch, senior, pay, eat, ...\n",
              "\n",
              "[5 rows x 10 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "buJpJUQ4aGHU"
      },
      "source": [
        "## Part 2: Vector Representation\n",
        "<a id=\"#p2\"></a>\n",
        "1. Create a vector representation of the reviews (i.e. create a doc-term matrix).\n",
        "2. Write a fake review and query for the 10 most similar reviews, print the text of the reviews. Do you notice any patterns?\n",
        "    - Given the size of the dataset, use `NearestNeighbors` model for this. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "d70a0a1a96cf8406c60b17e50b255a1a",
          "grade": false,
          "grade_id": "cell-0e96491cb529202c",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aFG4J2P8aGHV",
        "outputId": "122dc6b3-80d4-4a3f-f5a9-e46d1142ced5"
      },
      "source": [
        "# Create a vector representation of the reviews \n",
        "# Name that doc-term matrix \"dtm\"\n",
        "# making a new column of cleaned text from our spacy tokens\n",
        "df['token_text'] = [' '.join(token) for token in df['spacy_tokens']]"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 26.8 ms, sys: 999 µs, total: 27.8 ms\n",
            "Wall time: 32 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TtOHiZIRorsu"
      },
      "source": [
        "def count_vectorize(column):\n",
        "  '''Takes a column of cleaned text as input and outputs a document-term-matrix \n",
        "  dataframe'''\n",
        "  text = []\n",
        "  for row in column:\n",
        "    text.append(row)\n",
        "\n",
        "  vect = CountVectorizer(stop_words='english', max_features=1000)\n",
        "  vect.fit(text)\n",
        "  transformed = vect.transform(text)\n",
        "  dense = transformed.todense()\n",
        "\n",
        "  return pd.DataFrame(dense, columns = vect.get_feature_names())"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vGqH4diEn9FJ"
      },
      "source": [
        "dtm = count_vectorize(df['token_text'])"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "32b220e23c9aa1f602f08d1c2e879d0a",
          "grade": false,
          "grade_id": "cell-3d5bc610a8ec6b24",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RjraKzjaaGHX",
        "outputId": "45156b33-ebf1-48cd-f753-79905bcccc77"
      },
      "source": [
        "# Create and fit a NearestNeighbors model named \"nn\"\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "\n",
        "# YOUR CODE HERE\n",
        "nn = NearestNeighbors(n_neighbors=10, algorithm='kd_tree')\n",
        "nn.fit(dtm)"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "NearestNeighbors(algorithm='kd_tree', leaf_size=30, metric='minkowski',\n",
              "                 metric_params=None, n_jobs=None, n_neighbors=10, p=2,\n",
              "                 radius=1.0)"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4WGjQIeLsFnW"
      },
      "source": [
        "# testing our fit on the first document\n",
        "doc_index = 0\n",
        "doc = [dtm.iloc[doc_index].values]"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "irlJ2DhrtMZn",
        "outputId": "4c831049-75a2-47a9-932b-1212ac84a09d"
      },
      "source": [
        "# we get the most similar documents, as expected\n",
        "neigh_dist, neigh_index = nn.kneighbors(doc)\n",
        "neigh_index"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[   0, 8470, 3546,  869,  262, 2793, 6204, 5465, 5320, 8413]])"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "d270ed23df3c7d3c6cf08ab174ccaf9e",
          "grade": true,
          "grade_id": "cell-c43704dcff67e99b",
          "locked": true,
          "points": 1,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "M0Cs9aMlaGHX"
      },
      "source": [
        "'''Testing.'''\n",
        "assert nn.__module__ == 'sklearn.neighbors._unsupervised', ' nn is not a NearestNeighbors instance.'\n",
        "assert nn.n_neighbors == 10, 'nn has the wrong value for n_neighbors'"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "3da2ced9f187ed0aa1a890785e2ba00e",
          "grade": false,
          "grade_id": "cell-496203e8746296ca",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "cwO6HhdHaGHY",
        "outputId": "da41b03c-2958-4680-b1d7-36725045d02c"
      },
      "source": [
        "# Create a fake review and find the 10 most similar reviews\n",
        "fake_review = 'This restaurant served food that was delicious. \\\n",
        "               The service was good and fast, the waiters were nice, \\\n",
        "               and the dessert was excellent!'\n",
        "# turning our fake review into a cleaned review\n",
        "def use_review(review):\n",
        "  tokens = tokenize(review)\n",
        "  review = ' '.join(tokens)\n",
        "  return review\n",
        "\n",
        "new_review = use_review(fake_review)\n",
        "new_review"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'restaurant serve food delicious service good fast waiter nice dessert excellent'"
            ]
          },
          "metadata": {},
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9rRSJF3KwPCg"
      },
      "source": [
        "# wasn't sure how to vectorize the fake review within the dtm dataframe, \n",
        "# so I created a new dtm with the fake review as the final row\n",
        "text = []\n",
        "for row in df['token_text']:\n",
        "  text.append(row)\n",
        "text.append(new_review)\n",
        "text[-1]\n",
        "vect = CountVectorizer(stop_words='english', max_features=1000)\n",
        "vect.fit(text)\n",
        "transformed = vect.transform(text)\n",
        "dense = transformed.todense()\n",
        "\n",
        "dtm2 = pd.DataFrame(dense, columns = vect.get_feature_names())"
      ],
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5q5rqK6YyH2q",
        "outputId": "def385fa-77c7-4e7c-f56e-847f19647719"
      },
      "source": [
        "# creating another nearest neighbors model...\n",
        "nn2 = NearestNeighbors(n_neighbors=10, algorithm='kd_tree')\n",
        "nn2.fit(dtm2)"
      ],
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "NearestNeighbors(algorithm='kd_tree', leaf_size=30, metric='minkowski',\n",
              "                 metric_params=None, n_jobs=None, n_neighbors=10, p=2,\n",
              "                 radius=1.0)"
            ]
          },
          "metadata": {},
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fl8-zdm3ySM_",
        "outputId": "c76108ff-2129-42f0-df52-f04a5c3d3d7d"
      },
      "source": [
        "# getting the closest reviews to our fake review...\n",
        "doc = [dtm2.iloc[-1].values]\n",
        "neigh_dist, neigh_index = nn2.kneighbors(doc)\n",
        "neigh_index"
      ],
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[10000,  9898,  4028,  1557,  3405,  7132,  8970,   805,  2634,\n",
              "          744]])"
            ]
          },
          "metadata": {},
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wr5yyZ7jyZkD",
        "outputId": "ac95db6d-97b8-49ee-f840-687d9d45e176"
      },
      "source": [
        "# let's see for ourselves how these reviews compare to our fake one\n",
        "print(f'Fake Review: {fake_review}')\n",
        "for i in neigh_index[0][1:]:\n",
        "  print('Review Text: ', {df.loc[i, 'text']}, \n",
        "        'Cleaned Text: ', {df['token_text'][i]}, \n",
        "        '\\nStars: ', {df['stars'][i]})\n",
        "# not bad!"
      ],
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fake Review: This restaurant served food that was delicious.                The service was good and fast, the waiters were nice,                and the dessert was excellent!\n",
            "Review Text:  {'Very yummy! Food and service were excellent!'} Cleaned Text:  {'yummy food service excellent'} \n",
            "Stars:  {5}\n",
            "Review Text:  {'Good food with so-so service; unless you are with Asians. Horrible to say but it is the unfortunate truth.'} Cleaned Text:  {'good food service asians horrible unfortunate truth'} \n",
            "Stars:  {4}\n",
            "Review Text:  {\"Très bon déjeuner, service impeccable prix raisonnable. Un des meilleurs Ben & Florentine que j'ai essayé.\"} Cleaned Text:  {'tr s bon d jeuner service impeccable prix raisonnable un des meilleur ben florentine que j ai essay'} \n",
            "Stars:  {5}\n",
            "Review Text:  {'Very nice. Great dining experience and service. Desserts were excellent.'} Cleaned Text:  {'nice great dining experience service dessert excellent'} \n",
            "Stars:  {4}\n",
            "Review Text:  {'Super good food. Great service. They even made me a jalapeño vodka margarita. Delicious burgers.'} Cleaned Text:  {'super good food great service jalape o vodka margarita delicious burger'} \n",
            "Stars:  {5}\n",
            "Review Text:  {'Food is very delish here, price is good,decent nice service and free wifi'} Cleaned Text:  {'food delish price good decent nice service free wifi'} \n",
            "Stars:  {5}\n",
            "Review Text:  {'Omg, they have the best Mexican food around! The nachos could feed an army.'} Cleaned Text:  {'omg good mexican food nachos feed army'} \n",
            "Stars:  {5}\n",
            "Review Text:  {'Good food and service. I will be there tomorrow for fish. Best coleslaw in the area.'} Cleaned Text:  {'good food service tomorrow fish good coleslaw area'} \n",
            "Stars:  {5}\n",
            "Review Text:  {'Pretty damn good. I had the Fettuccine Carbonara.  Very creamy.  Crabcakes were delicious as well.'} Cleaned Text:  {'pretty damn good fettuccine carbonara creamy crabcake delicious'} \n",
            "Stars:  {5}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j0x7V25iaGHZ"
      },
      "source": [
        "## Part 3: Classification\n",
        "<a id=\"#p3\"></a>\n",
        "Your goal in this section will be to predict `stars` from the review dataset. \n",
        "\n",
        "1. Create a pipeline object with a sklearn `CountVectorizer` or `TfidfVector` and any sklearn classifier.\n",
        "    - Use that pipeline to train a model to predict the `stars` feature (i.e. the labels). \n",
        "    - Use that Pipeline to predict a star rating for your fake review from Part 2. \n",
        "\n",
        "\n",
        "\n",
        "2. Create a parameter dict including `one parameter for the vectorizer` and `one parameter for the model`. \n",
        "    - Include 2 possible values for each parameter\n",
        "    - **Use `n_jobs` = 1** \n",
        "    - Due to limited computational resources on CodeGrader `DO NOT INCLUDE ADDITIONAL PARAMETERS OR VALUES PLEASE.`\n",
        "    \n",
        "    \n",
        "3. Train the entire pipeline with a GridSearch\n",
        "    - Name your GridSearch object as `gs`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OPxi5zIb4iQn"
      },
      "source": [
        "from sklearn.ensemble import RandomForestRegressor"
      ],
      "execution_count": 108,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "jupyter": {
          "outputs_hidden": true
        },
        "nbgrader": {
          "cell_type": "code",
          "checksum": "e1d18da8521d51d8bfc4b5b9d005fa34",
          "grade": false,
          "grade_id": "cell-e2beb0252d274bba",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QVScrDG3aGHa",
        "outputId": "f6ee469d-984f-4adc-a159-59812177a3c9"
      },
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "tfidf = TfidfVectorizer(stop_words='english', tokenizer = None)\n",
        "rfr = RandomForestRegressor(random_state=42)\n",
        "# Name the gridsearch instance \"gs\"\n",
        "pipe = Pipeline([('vect', tfidf),\n",
        "                ('clf', rfr)])\n",
        "parameters = {\n",
        "    'vect__max_features': (500, 1000),\n",
        "    'clf__max_depth':(15, 20)\n",
        "}\n",
        "\n",
        "gs = GridSearchCV(pipe, param_grid=parameters, n_jobs=-1, cv=3, verbose=1)\n",
        "\n",
        "X = df['token_text']\n",
        "y = df['stars']\n",
        "\n",
        "gs.fit(X,y)"
      ],
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  20 out of  20 | elapsed: 11.7min finished\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=5, error_score=nan,\n",
              "             estimator=Pipeline(memory=None,\n",
              "                                steps=[('vect',\n",
              "                                        TfidfVectorizer(analyzer='word',\n",
              "                                                        binary=False,\n",
              "                                                        decode_error='strict',\n",
              "                                                        dtype=<class 'numpy.float64'>,\n",
              "                                                        encoding='utf-8',\n",
              "                                                        input='content',\n",
              "                                                        lowercase=True,\n",
              "                                                        max_df=1.0,\n",
              "                                                        max_features=None,\n",
              "                                                        min_df=1,\n",
              "                                                        ngram_range=(1, 1),\n",
              "                                                        norm='l2',\n",
              "                                                        preprocessor=None,\n",
              "                                                        smooth_idf=True,\n",
              "                                                        stop_words='english',\n",
              "                                                        strip...\n",
              "                                                              min_samples_leaf=1,\n",
              "                                                              min_samples_split=2,\n",
              "                                                              min_weight_fraction_leaf=0.0,\n",
              "                                                              n_estimators=100,\n",
              "                                                              n_jobs=None,\n",
              "                                                              oob_score=False,\n",
              "                                                              random_state=42,\n",
              "                                                              verbose=0,\n",
              "                                                              warm_start=False))],\n",
              "                                verbose=False),\n",
              "             iid='deprecated', n_jobs=-1,\n",
              "             param_grid={'clf__max_depth': (15, 20),\n",
              "                         'vect__max_features': (500, 1000)},\n",
              "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
              "             scoring=None, verbose=1)"
            ]
          },
          "metadata": {},
          "execution_count": 114
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vePm1654GUs6",
        "outputId": "86d4832b-061c-48d6-ea05-3c6cd88dc36a"
      },
      "source": [
        "gs.best_params_"
      ],
      "execution_count": 142,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'clf__max_depth': 20, 'vect__max_features': 1000}"
            ]
          },
          "metadata": {},
          "execution_count": 142
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nJvF3OjSGatr"
      },
      "source": [
        "# I do not know why the test cell didn't work, so I deleted it. The grid search took like "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Aucy-SA9aGHb"
      },
      "source": [
        "## Part 4: Topic Modeling\n",
        "\n",
        "Let's find out what those yelp reviews are saying! :D\n",
        "\n",
        "1. Estimate a LDA topic model of the review text\n",
        "    - Set num_topics to `5`\n",
        "    - Name your LDA model `lda`\n",
        "2. Create 1-2 visualizations of the results\n",
        "    - You can use the most important 3 words of a topic in relevant visualizations. Refer to yesterday's notebook to extract. \n",
        "3. In markdown, write 1-2 paragraphs of analysis on the results of your topic model\n",
        "\n",
        "When you instantiate your LDA model, it should look like this: \n",
        "\n",
        "```python\n",
        "lda = LdaModel(corpus=corpus,\n",
        "               id2word=id2word,\n",
        "               random_state=723812,\n",
        "               num_topics = num_topics,\n",
        "               passes=1\n",
        "              )\n",
        "\n",
        "```\n",
        "\n",
        "__*Note*__: You can pass the DataFrame column of text reviews to gensim. You do not have to use a generator."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tl1UVgav9JWC"
      },
      "source": [
        "import gensim\n",
        "import gensim.corpora as corpora\n",
        "from gensim.utils import simple_preprocess\n",
        "from gensim.models import CoherenceModel\n",
        "from pandarallel import pandarallel\n"
      ],
      "execution_count": 117,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JKqcaD9B_pMO"
      },
      "source": [
        "def filter_tokens(tokens):\n",
        "  return [token for token in tokens if (len(token) > 2)]"
      ],
      "execution_count": 134,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F8Fsu8j8_dk-",
        "outputId": "af4475a4-3dea-4a6f-c177-0cb752d9e151"
      },
      "source": [
        "new_tokens = df['spacy_tokens'].apply(lambda x: filter_tokens(x))\n",
        "new_tokens"
      ],
      "execution_count": 135,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0       [beware, fake, fake, fake, small, business, lo...\n",
              "1       [come, lunch, togo, service, quick, staff, fri...\n",
              "2       [vegas, dozen, time, step, foot, circus, circu...\n",
              "3       [night, close, street, party, good, actually, ...\n",
              "4       [star, bad, price, lunch, senior, pay, eat, ho...\n",
              "                              ...                        \n",
              "9995    [family, hungry, subway, open, hour, guy, work...\n",
              "9996    [wife, come, couple, friend, sever, excited, p...\n",
              "9997    [food, brag, food, hot, item, tasty, horrible,...\n",
              "9998    [today, visit, great, love, enjoy, town, squar...\n",
              "9999    [absolute, bad, place, stay, year, life, time,...\n",
              "Name: spacy_tokens, Length: 10000, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 135
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FQfKwVSK6puy"
      },
      "source": [
        "id2word = corpora.Dictionary(new_tokens)\n",
        "corpus = [id2word.doc2bow(text) for text in new_tokens]"
      ],
      "execution_count": 137,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vp3SBOi2-FCk",
        "outputId": "2f5ed603-a21a-4500-dbfe-f2d50d3c5e83"
      },
      "source": [
        "doc_id = 1\n",
        "[(id2word[word_id], word_count) for word_id, word_count in corpus[doc_id]]"
      ],
      "execution_count": 138,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('come', 1),\n",
              " ('complaint', 1),\n",
              " ('friendly', 1),\n",
              " ('good', 1),\n",
              " ('lunch', 1),\n",
              " ('pain', 1),\n",
              " ('parking', 1),\n",
              " ('quick', 1),\n",
              " ('service', 1),\n",
              " ('staff', 1),\n",
              " ('sweet', 1),\n",
              " ('tea', 1),\n",
              " ('togo', 1)]"
            ]
          },
          "metadata": {},
          "execution_count": 138
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9L_UtzH--Se6"
      },
      "source": [
        "num_topics = 3\n",
        "lda_multicore_topics = gensim.models.ldamulticore.LdaMulticore(corpus=corpus,\n",
        "                                                        id2word=id2word,\n",
        "                                                        num_topics=num_topics, \n",
        "                                                        chunksize=100,\n",
        "                                                        passes=10,# runtime related parameter\n",
        "                                                        per_word_topics=True,\n",
        "                                                        workers=10, # runtime related parameter\n",
        "                                                        random_state=42, \n",
        "                                                        iterations=20) # runtime related parameter"
      ],
      "execution_count": 139,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "amfE4tTk-28H"
      },
      "source": [
        "import pyLDAvis\n",
        "import pyLDAvis.gensim "
      ],
      "execution_count": 128,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 882
        },
        "id": "d23g1naG-Mfd",
        "outputId": "854f54d1-844a-4e6a-e97d-d2523de733b9"
      },
      "source": [
        "pyLDAvis.enable_notebook()\n",
        "vis = pyLDAvis.gensim.prepare(lda_multicore_topics, corpus, id2word)\n",
        "vis"
      ],
      "execution_count": 141,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.css\">\n",
              "\n",
              "\n",
              "<div id=\"ldavis_el1601406509692832807173381390\"></div>\n",
              "<script type=\"text/javascript\">\n",
              "\n",
              "var ldavis_el1601406509692832807173381390_data = {\"mdsDat\": {\"x\": [-0.12460626110516082, 0.13606702462314244, -0.011460763517981646], \"y\": [-0.049956591149568054, -0.038313889434647606, 0.08827048058421567], \"topics\": [1, 2, 3], \"cluster\": [1, 1, 1], \"Freq\": [39.80292946779074, 38.182723607644476, 22.014346924564784]}, \"tinfo\": {\"Term\": [\"food\", \"drink\", \"order\", \"service\", \"chicken\", \"place\", \"bar\", \"restaurant\", \"table\", \"great\", \"wait\", \"good\", \"cheese\", \"fresh\", \"sauce\", \"eat\", \"taste\", \"beer\", \"server\", \"delicious\", \"room\", \"flavor\", \"car\", \"time\", \"fry\", \"menu\", \"meat\", \"salad\", \"dish\", \"coffee\", \"pork\", \"beef\", \"rice\", \"cream\", \"noodle\", \"shrimp\", \"spicy\", \"crispy\", \"crab\", \"chocolate\", \"fried\", \"meat\", \"garlic\", \"tomato\", \"cheese\", \"crust\", \"pepper\", \"topping\", \"lamb\", \"butter\", \"mushroom\", \"onion\", \"raman\", \"flavorful\", \"bread\", \"broth\", \"corn\", \"cookie\", \"yum\", \"creamy\", \"flavor\", \"chicken\", \"soup\", \"egg\", \"fresh\", \"sauce\", \"bacon\", \"bbq\", \"salmon\", \"potato\", \"salad\", \"thai\", \"fry\", \"dish\", \"bean\", \"taste\", \"dessert\", \"delicious\", \"cake\", \"ice\", \"tasty\", \"sweet\", \"portion\", \"pizza\", \"fish\", \"burger\", \"good\", \"try\", \"order\", \"menu\", \"eat\", \"like\", \"place\", \"food\", \"little\", \"love\", \"restaurant\", \"come\", \"great\", \"meal\", \"get\", \"time\", \"nice\", \"definitely\", \"think\", \"service\", \"price\", \"appointment\", \"nail\", \"salon\", \"office\", \"repair\", \"massage\", \"hair\", \"car\", \"company\", \"pedicure\", \"doctor\", \"schedule\", \"gym\", \"spa\", \"class\", \"tire\", \"email\", \"insurance\", \"patient\", \"vehicle\", \"haircut\", \"pool\", \"property\", \"tech\", \"stylist\", \"vet\", \"rent\", \"quote\", \"apartment\", \"bike\", \"professional\", \"sale\", \"contact\", \"phone\", \"job\", \"store\", \"wedding\", \"room\", \"bed\", \"call\", \"desk\", \"hotel\", \"purchase\", \"help\", \"work\", \"guy\", \"tell\", \"care\", \"need\", \"stay\", \"shop\", \"fix\", \"day\", \"year\", \"charge\", \"say\", \"customer\", \"time\", \"know\", \"buy\", \"look\", \"find\", \"take\", \"get\", \"new\", \"want\", \"service\", \"like\", \"recommend\", \"come\", \"great\", \"experience\", \"feel\", \"don\", \"ask\", \"place\", \"good\", \"people\", \"staff\", \"bartender\", \"les\", \"est\", \"yuk\", \"une\", \"des\", \"barista\", \"que\", \"pas\", \"ipa\", \"vous\", \"mais\", \"bon\", \"tait\", \"karaoke\", \"bowling\", \"sont\", \"avec\", \"nous\", \"sur\", \"vinny\", \"victor\", \"comme\", \"belle\", \"qui\", \"doughnut\", \"tout\", \"ethiopian\", \"cheesetart\", \"res\", \"starbucks\", \"pub\", \"drink\", \"beer\", \"pour\", \"bar\", \"patron\", \"tap\", \"waitress\", \"coffee\", \"table\", \"slow\", \"food\", \"hostess\", \"server\", \"waiter\", \"wait\", \"seat\", \"atmosphere\", \"refill\", \"service\", \"music\", \"sit\", \"minute\", \"great\", \"place\", \"order\", \"restaurant\", \"night\", \"wine\", \"come\", \"time\", \"busy\", \"good\", \"friendly\", \"staff\", \"hour\", \"ask\", \"bad\", \"people\", \"eat\", \"experience\", \"like\", \"don\", \"get\", \"love\", \"want\", \"price\"], \"Freq\": [4897.0, 1370.0, 3348.0, 3680.0, 1387.0, 5192.0, 1020.0, 1698.0, 1103.0, 4150.0, 1659.0, 6115.0, 864.0, 941.0, 916.0, 1487.0, 1162.0, 609.0, 812.0, 1200.0, 1132.0, 744.0, 670.0, 4216.0, 871.0, 1252.0, 663.0, 769.0, 866.0, 627.0, 351.76884133117034, 465.0265005497981, 526.8706875445533, 587.1347352272594, 287.5180527267725, 363.8114007895638, 361.4300263998665, 198.18634436499653, 169.48475474695528, 330.83639528593045, 222.35077093992857, 660.4234572763069, 168.21239415116204, 199.89558248270777, 859.9077100483559, 144.59213263958918, 162.04363136267972, 151.6100975992088, 152.26750878049936, 203.3085755011746, 138.45602594563724, 218.0351033301337, 136.40415309743364, 170.30199728055456, 494.9573035947253, 125.6048578093751, 151.27118836088192, 163.90038570429525, 125.79931302358948, 112.88880232962966, 739.313462323543, 1368.2730267819124, 493.93313595028667, 409.36994701155606, 923.2738877237352, 898.8736607099634, 209.46854966570578, 236.094211032125, 217.7090730187289, 341.06126832351754, 749.1882938657984, 218.379838486476, 833.8400544461598, 825.3046313038028, 228.10122839295565, 1072.7083531726864, 496.37259264217164, 1081.2244966167154, 241.01617209094618, 467.3150361169273, 480.1977659153032, 548.0424494782135, 442.4769034780582, 713.1350811144355, 359.09813362124504, 586.6851556563856, 3523.003684638365, 1589.364205504241, 1953.6742695003302, 898.792385284443, 1017.425233240821, 1893.8576788529022, 2286.637666550655, 2086.8407377536582, 883.7516558580762, 1172.1723168469393, 958.9306285136096, 1413.4783477051794, 1399.0036277710115, 643.6199620376736, 1000.3268824323454, 1095.4377024776911, 791.5258923212473, 697.6063895985052, 706.7128632551008, 785.8259114178564, 715.3866491866055, 360.14873660158975, 338.929269288166, 224.85010870132191, 328.5778916357489, 180.0903604547427, 174.24618262571298, 396.15157160580605, 667.2631215030614, 397.5439070674217, 139.03253072516674, 138.580837215154, 164.5197079331957, 116.30841170181083, 111.4475074284093, 220.0265866180172, 126.13510247841752, 118.34814306664404, 104.46809876661729, 171.4337905549887, 102.32696357151285, 96.9925939763911, 281.6022544187482, 89.85365615555602, 88.43137252235645, 84.33570554120975, 79.21855033152308, 93.6035511344027, 105.09068986341319, 80.56821707204516, 76.96184319097881, 347.0386275541619, 144.757212804406, 122.26259391605319, 361.44231945209, 482.27364740444375, 759.5876078630611, 126.54980617876848, 1025.867745648804, 165.35758863031955, 712.6958128006436, 139.3876350188952, 467.64379590764895, 261.202268341507, 523.3854877706617, 1078.126286994674, 528.2963516178353, 1044.1685388179858, 503.1088788280551, 943.436039656527, 513.7779361645972, 426.2224204025524, 293.2728150938339, 994.0263914900581, 685.0981060714448, 404.8322569950013, 945.4504571808606, 740.7633579837575, 1804.492888669815, 905.356727389978, 384.6471893474062, 995.5605353618795, 844.2415869614869, 809.5710213976922, 1205.3084513616084, 678.0113760582258, 834.7895876857317, 1189.501076784078, 1183.9322439716934, 698.7411101691894, 1119.8628394330126, 1161.5002150651708, 703.1240208385525, 636.5945818598304, 765.4978328637002, 703.0976783250205, 1051.1742899933097, 1068.8184292019816, 670.8443883387223, 668.6734852549365, 240.09659646920394, 48.94914793418879, 49.56962392516243, 45.083178357259776, 33.477094849177384, 32.77554671194522, 33.69825712063484, 30.701510329523586, 27.53597303578306, 35.66736653733812, 26.181304826814454, 25.058165631939257, 22.773729619596544, 21.433084485965917, 19.910955627817362, 19.29549486577155, 17.405543829213528, 15.53538773767696, 15.238258734352609, 13.958088304187912, 13.583295859423403, 16.005703402849246, 13.119837346634611, 12.57268137345028, 12.464892165681524, 17.090995274270295, 12.294686974124273, 12.611233366375847, 11.674368425570492, 11.947987301334805, 79.99822998407981, 50.86008314103673, 1125.4367169511943, 512.4208675434435, 84.02928175965184, 796.4963962654153, 71.85265443619973, 95.92248827027785, 361.84132302071174, 462.6232792228587, 746.7407273712606, 181.3099447720164, 2807.2464532015515, 98.58847452290166, 529.8960834648638, 227.7064955672255, 957.6343779773945, 397.20532400061836, 296.8614429246172, 100.58945456537307, 1704.7123194977896, 195.18152075934103, 424.8253590600701, 538.5308983396433, 1589.8108292541403, 1854.272028453016, 1265.326000650806, 731.0784165861002, 481.8409639047405, 241.6732707187151, 1236.5899158910745, 1317.0032130080597, 273.4832673980965, 1524.0637551745674, 522.3519563036618, 565.481665543636, 426.8755956514505, 524.1530242156556, 423.8474673760697, 463.91921070924855, 463.19870528181127, 446.62214012161826, 629.1329639583091, 484.8797065506409, 538.3303992393672, 490.94388719367976, 454.3659837566984, 435.0969881316135], \"Total\": [4897.0, 1370.0, 3348.0, 3680.0, 1387.0, 5192.0, 1020.0, 1698.0, 1103.0, 4150.0, 1659.0, 6115.0, 864.0, 941.0, 916.0, 1487.0, 1162.0, 609.0, 812.0, 1200.0, 1132.0, 744.0, 670.0, 4216.0, 871.0, 1252.0, 663.0, 769.0, 866.0, 627.0, 352.51241438498107, 466.0988971884769, 528.1735850436748, 588.6098920123982, 288.386359516619, 364.93262707767144, 362.56138598312475, 198.91619653033166, 170.18659333227808, 332.2806337929922, 223.34487612787095, 663.3811313920149, 168.96976258549836, 200.83673493944517, 864.0624189920745, 145.30523359163976, 162.8464683385565, 152.37636958041608, 153.04027451600936, 204.35876705400784, 139.1741377783059, 219.20480229748728, 137.13716796272416, 171.2408356036995, 497.7080933140261, 126.30757157510963, 152.12370820969792, 164.85469759387337, 126.5433001315197, 113.56540511361416, 744.81008614253, 1387.8072589143712, 498.0728524222831, 413.00813394731813, 941.5374672975793, 916.5827718008163, 210.78530996452278, 238.190527374629, 219.56304274676611, 345.58924668168925, 769.7924231090444, 220.41249770212303, 871.3329945338929, 866.8424441193456, 230.58926597617307, 1162.6018197987416, 519.4960517629466, 1200.676440520901, 244.54849457567008, 500.8838284467697, 518.516428850713, 613.1718236666693, 482.33856886288135, 839.5069925445067, 386.8880985239075, 691.2365632025248, 6115.8858690149145, 2483.374281841015, 3348.9557370135617, 1252.7589598270188, 1487.7140309445456, 3706.9228867829047, 5192.083984996981, 4897.399235102061, 1367.8798911036574, 2199.082087271379, 1698.82737979906, 3769.9311030292665, 4150.314672090322, 857.2157758050579, 2743.9657330333207, 4216.933804155566, 1709.8222655276984, 1366.4498068856874, 1458.0042996054244, 3680.0393076997243, 1770.4894348714136, 360.8174826047262, 339.68496123760826, 225.5420319988126, 329.72768388062764, 180.7452599697565, 174.9348749314444, 397.7906289001352, 670.1167651413123, 399.25326653130026, 139.68271666633837, 139.2937661312718, 165.4012974819064, 116.98530613263017, 112.11536807957826, 221.34553934468767, 126.91336471473457, 119.08089763726431, 105.11911274269659, 172.53956555505812, 103.0151749746018, 97.65103792466597, 283.53694823871774, 90.5402571241734, 89.10986696579896, 84.98595025460071, 79.87613022103463, 94.38111591274308, 105.96410895403467, 81.259747244834, 77.62384583347783, 350.78843295773197, 146.39919570627106, 123.67069006336995, 372.2111490892844, 502.38326954446995, 805.4305863433145, 128.5282098876361, 1132.1027627583085, 169.69941953314986, 781.1007214177235, 142.26547401834387, 519.0497392979134, 281.0761558661768, 628.7458957862115, 1448.625852685722, 656.4339622739393, 1481.6745193025245, 634.216843508851, 1362.2806761395425, 661.3432923458962, 533.2802230666966, 340.6031381263277, 1515.4303739224492, 959.1269593245548, 505.7438985246265, 1493.1943008282526, 1112.439523265087, 4216.933804155566, 1602.6797518765493, 481.7854184195587, 1896.6118398717178, 1524.4209480689374, 1446.686167737953, 2743.9657330333207, 1130.0296379945, 1788.2570815683564, 3680.0393076997243, 3706.9228867829047, 1352.012015682718, 3769.9311030292665, 4150.314672090322, 1398.638487793537, 1125.1557772567567, 1824.7322667221606, 1482.8750489913728, 5192.083984996981, 6115.8858690149145, 1413.038606218409, 1558.9076736649777, 241.95248414458857, 49.59488350908874, 50.22609160439632, 45.72595264522844, 34.1195937319782, 33.4244091411576, 34.45328058478016, 31.406502346066922, 28.18482315264069, 36.51655046299703, 26.824150727429164, 25.700590213860714, 23.450731271858583, 22.075447964715536, 20.570763547307052, 19.975499934576682, 18.048210564460515, 16.177800115480977, 15.880791164565514, 14.610854092688136, 14.248283820194565, 16.791599375093917, 13.767473195432952, 13.215105831274531, 13.107392210148522, 17.99596164761395, 12.94654932694849, 13.30069952255373, 12.317004115843389, 12.60902632577571, 85.17210340499658, 54.139225309528435, 1370.900358114003, 609.8995311660599, 94.78127963862012, 1020.4787797125493, 82.71494647495788, 112.53799959908312, 468.365679367168, 627.7907878331819, 1103.263392289152, 236.51216682978648, 4897.399235102061, 123.29924774400837, 812.2555971957274, 319.1901046237296, 1659.1593550859716, 616.9843513011444, 457.94587430012393, 129.78443154791984, 3680.0393076997243, 288.216247529286, 736.9937143320462, 1058.947371896707, 4150.314672090322, 5192.083984996981, 3348.9557370135617, 1698.82737979906, 1034.0874178574322, 414.29568936027397, 3769.9311030292665, 4216.933804155566, 512.9007810313019, 6115.8858690149145, 1382.5759583844463, 1558.9076736649777, 1046.5864815967363, 1482.8750489913728, 1174.4796310491572, 1413.038606218409, 1487.7140309445456, 1398.638487793537, 3706.9228867829047, 1824.7322667221606, 2743.9657330333207, 2199.082087271379, 1788.2570815683564, 1770.4894348714136], \"Category\": [\"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\"], \"logprob\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, -6.291399955749512, -6.01230001449585, -5.887400150299072, -5.779099941253662, -6.493100166320801, -6.257699966430664, -6.2642998695373535, -6.865200042724609, -7.021599769592285, -6.352700233459473, -6.750100135803223, -5.661499977111816, -7.029099941253662, -6.856599807739258, -5.397500038146973, -7.1803998947143555, -7.066500186920166, -7.1331000328063965, -7.128699779510498, -6.839600086212158, -7.223800182342529, -6.769700050354004, -7.238699913024902, -7.0167999267578125, -5.949900150299072, -7.321199893951416, -7.135300159454346, -7.055099964141846, -7.319699764251709, -7.427999973297119, -5.548600196838379, -4.93310022354126, -5.952000141143799, -6.139699935913086, -5.326399803161621, -5.3531999588012695, -6.809800148010254, -6.690100193023682, -6.771200180053711, -6.322299957275391, -5.535399913787842, -6.768099784851074, -5.428299903869629, -5.438600063323975, -6.724599838256836, -5.176400184631348, -5.947000026702881, -5.168499946594238, -6.66949987411499, -6.007400035858154, -5.980199813842773, -5.8480000495910645, -6.061999797821045, -5.584700107574463, -6.2708001136779785, -5.779900074005127, -3.987299919128418, -4.783299922943115, -4.576900005340576, -5.353300094604492, -5.229300022125244, -4.607999801635742, -4.41949987411499, -4.511000156402588, -5.370200157165527, -5.087800025939941, -5.28849983215332, -4.900599956512451, -4.910799980163574, -5.687300205230713, -5.246300220489502, -5.1554999351501465, -5.480400085449219, -5.6066999435424805, -5.593699932098389, -5.487599849700928, -5.581500053405762, -6.22629976272583, -6.2870001792907715, -6.697400093078613, -6.317999839782715, -6.919300079345703, -6.952300071716309, -6.13100004196167, -5.609600067138672, -6.127500057220459, -7.178100109100342, -7.181399822235107, -7.009799957275391, -7.356599807739258, -7.3993000984191895, -6.719099998474121, -7.2754998207092285, -7.339200019836426, -7.463900089263916, -6.968599796295166, -7.484600067138672, -7.5381999015808105, -6.472300052642822, -7.61460018157959, -7.6305999755859375, -7.677999973297119, -7.740600109100342, -7.573699951171875, -7.458000183105469, -7.723700046539307, -7.769499778747559, -6.263400077819824, -7.137800216674805, -7.306600093841553, -6.222700119018555, -5.934299945831299, -5.480000019073486, -7.272200107574463, -5.179500102996826, -7.004700183868408, -5.543799877166748, -7.17549991607666, -5.965099811553955, -6.547500133514404, -5.852499961853027, -5.129799842834473, -5.843200206756592, -5.161799907684326, -5.892000198364258, -5.263299942016602, -5.870999813079834, -6.057799816131592, -6.431700229644775, -5.210999965667725, -5.583199977874756, -6.109300136566162, -5.261099815368652, -5.505099773406982, -4.614799976348877, -5.304500102996826, -6.1605000495910645, -5.209499835968018, -5.3744001388549805, -5.416299819946289, -5.0183000564575195, -5.593599796295166, -5.3856000900268555, -5.031499862670898, -5.036200046539307, -5.563499927520752, -5.091800212860107, -5.055300235748291, -5.557300090789795, -5.656700134277344, -5.472300052642822, -5.557300090789795, -5.155099868774414, -5.138500213623047, -5.604300022125244, -5.607500076293945, -6.081099987030029, -7.671299934387207, -7.658699989318848, -7.753600120544434, -8.051300048828125, -8.072400093078613, -8.044699668884277, -8.137800216674805, -8.246600151062012, -7.9878997802734375, -8.297100067138672, -8.340900421142578, -8.43649959564209, -8.497200012207031, -8.570799827575684, -8.60219955444336, -8.705300331115723, -8.819000244140625, -8.838299751281738, -8.92609977722168, -8.953300476074219, -8.789199829101562, -8.98799991607666, -9.030599594116211, -9.039199829101562, -8.723600387573242, -9.053000450134277, -9.02750015258789, -9.104700088500977, -9.081600189208984, -7.180099964141846, -7.632999897003174, -4.536200046539307, -5.322999954223633, -7.13100004196167, -4.881899833679199, -7.287499904632568, -6.998600006103516, -5.670899868011475, -5.42519998550415, -4.946400165557861, -6.3618998527526855, -3.6222000122070312, -6.971199989318848, -5.289400100708008, -6.134099960327148, -4.697700023651123, -5.577700138092041, -5.868899822235107, -6.951099872589111, -4.120999813079834, -6.2881999015808105, -5.51039981842041, -5.2733001708984375, -4.190700054168701, -4.036900043487549, -4.419000148773193, -4.967599868774414, -5.384500026702881, -6.07450008392334, -4.441999912261963, -4.379000186920166, -5.950900077819824, -4.232999801635742, -5.303800106048584, -5.224400043487549, -5.5055999755859375, -5.300300121307373, -5.512700080871582, -5.422399997711182, -5.423999786376953, -5.460400104522705, -5.117800235748291, -5.378200054168701, -5.273600101470947, -5.365799903869629, -5.44320011138916, -5.486599922180176], \"loglift\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, 0.9191, 0.9189, 0.9188, 0.9187, 0.9182, 0.9182, 0.9181, 0.9176, 0.9171, 0.9169, 0.9168, 0.9168, 0.9167, 0.9165, 0.9164, 0.9163, 0.9163, 0.9162, 0.9162, 0.9161, 0.9161, 0.9159, 0.9159, 0.9157, 0.9157, 0.9157, 0.9156, 0.9154, 0.9153, 0.9153, 0.9138, 0.9071, 0.9129, 0.9124, 0.9016, 0.9017, 0.915, 0.9124, 0.9127, 0.908, 0.8941, 0.912, 0.8772, 0.8721, 0.9104, 0.8408, 0.8757, 0.8164, 0.9067, 0.8519, 0.8445, 0.8089, 0.835, 0.7581, 0.8467, 0.7572, 0.3697, 0.4749, 0.3823, 0.5892, 0.5413, 0.2496, 0.1012, 0.0682, 0.4844, 0.292, 0.3494, -0.0598, -0.1662, 0.6346, -0.0878, -0.4267, 0.151, 0.2489, 0.197, -0.6227, 0.015, 0.9609, 0.9606, 0.9597, 0.9593, 0.9592, 0.9588, 0.9587, 0.9585, 0.9585, 0.9581, 0.9577, 0.9574, 0.957, 0.9568, 0.9568, 0.9566, 0.9566, 0.9566, 0.9564, 0.9561, 0.956, 0.9559, 0.9552, 0.9551, 0.9551, 0.9545, 0.9545, 0.9545, 0.9542, 0.9542, 0.952, 0.9515, 0.9513, 0.9334, 0.9219, 0.9042, 0.9473, 0.8642, 0.9369, 0.8711, 0.9424, 0.8585, 0.8895, 0.7794, 0.6674, 0.7456, 0.6128, 0.7312, 0.5954, 0.7103, 0.7387, 0.8132, 0.5411, 0.6263, 0.7402, 0.5058, 0.5562, 0.114, 0.3917, 0.7376, 0.3183, 0.3719, 0.3823, 0.1401, 0.452, 0.201, -0.1666, -0.1786, 0.3027, -0.2511, -0.3107, 0.2751, 0.3932, 0.0941, 0.2165, -0.6344, -0.7815, 0.2178, 0.1163, 1.5058, 1.5004, 1.5003, 1.4993, 1.4945, 1.4939, 1.4913, 1.4908, 1.4902, 1.4899, 1.4892, 1.4882, 1.4842, 1.4839, 1.4809, 1.4788, 1.4772, 1.473, 1.4722, 1.4678, 1.4657, 1.4655, 1.4653, 1.4636, 1.4632, 1.4619, 1.4618, 1.4602, 1.4599, 1.4596, 1.4508, 1.451, 1.3162, 1.3393, 1.3931, 1.2657, 1.3727, 1.3537, 1.2554, 1.2082, 1.1232, 1.2477, 0.957, 1.2898, 1.0863, 1.1757, 0.9639, 1.0731, 1.08, 1.2586, 0.7439, 1.1237, 0.9626, 0.8373, 0.5539, 0.4838, 0.5402, 0.6703, 0.7498, 0.9745, 0.3988, 0.3497, 0.8846, 0.124, 0.5401, 0.4994, 0.6167, 0.4735, 0.4943, 0.3997, 0.3466, 0.3719, -0.2601, 0.1882, -0.1152, 0.014, 0.1434, 0.11]}, \"token.table\": {\"Topic\": [2, 2, 1, 2, 3, 1, 2, 3, 3, 1, 3, 1, 2, 3, 1, 2, 3, 3, 1, 2, 3, 1, 3, 1, 3, 1, 2, 1, 3, 1, 2, 3, 3, 2, 3, 3, 1, 3, 1, 1, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 2, 3, 1, 2, 3, 1, 2, 3, 1, 3, 3, 1, 3, 1, 2, 3, 2, 3, 1, 2, 3, 1, 2, 3, 3, 2, 3, 2, 3, 1, 3, 1, 1, 1, 2, 3, 1, 1, 1, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 3, 3, 2, 3, 1, 3, 1, 2, 3, 2, 1, 2, 3, 1, 3, 1, 2, 3, 1, 2, 3, 1, 3, 2, 3, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 3, 1, 2, 3, 1, 3, 1, 3, 1, 2, 3, 1, 2, 3, 1, 3, 1, 2, 3, 1, 3, 1, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 2, 2, 3, 2, 1, 2, 3, 1, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 2, 1, 3, 1, 2, 3, 3, 1, 2, 3, 1, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 3, 2, 1, 2, 3, 1, 3, 1, 2, 3, 1, 2, 3, 1, 1, 2, 3, 2, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 3, 3, 1, 2, 1, 3, 1, 2, 3, 3, 1, 2, 1, 2, 3, 2, 1, 2, 3, 1, 1, 2, 3, 1, 2, 3, 1, 2, 3, 2, 3, 1, 1, 2, 3, 1, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 2, 1, 3, 1, 2, 3, 3, 3, 2, 3, 1, 1, 2, 3, 1, 3, 2, 2, 3, 1, 2, 3, 1, 3, 1, 2, 3, 1, 3, 2, 3, 1, 3, 2, 1, 3, 1, 2, 3, 2, 1, 2, 3, 1, 3, 1, 2, 3, 1, 2, 3, 1, 3, 1, 2, 3, 1, 2, 3, 3, 1, 3, 2, 1, 3, 1, 2, 3, 2, 3, 1, 2, 3, 1, 2, 3, 2, 3, 1, 2, 3, 1, 2, 3, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 3, 2, 1, 2, 3, 1, 3, 1, 2, 3, 1, 2, 3, 2, 1, 3, 1, 3, 1, 2, 3, 3, 2, 2, 3, 3, 3, 1, 2, 3, 1, 3, 1, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 3, 1], \"Freq\": [0.996803494305103, 0.9977343597687539, 0.1726376070418927, 0.47407905371269754, 0.3533676019138741, 0.329733290491529, 0.021836641754405896, 0.6485482601058551, 0.9890096234214913, 0.9915301974088078, 0.0047441636239655876, 0.2213746353078454, 0.41720604346478557, 0.361010943732794, 0.19892623348540522, 0.020578575877800542, 0.7800260189871062, 0.9868436161350511, 0.0041330429135102795, 0.0041330429135102795, 0.991930299242467, 0.9908034656173219, 0.008396639539129848, 0.9887710906003725, 0.008673430619301512, 0.02357108828659618, 0.9723073918220925, 0.9976423518804582, 0.002145467423398835, 0.15740297392335867, 0.0016396143117016527, 0.8394825275912462, 0.9837227310911527, 0.9919632192043649, 0.9807796496137641, 0.9511651804574796, 0.9945588722578449, 0.004018419685890283, 0.99756489994009, 0.849202763928469, 0.15045500417131308, 0.2573597172821309, 0.2105670414126526, 0.5322666880153163, 0.993351070406249, 0.004893355026631769, 0.004893355026631769, 0.14529289871334608, 0.7991109429234033, 0.05604154664657634, 0.9854896077695049, 0.0122675054909067, 0.0040891684969689, 0.06017149736424958, 0.9128144174619138, 0.02816538174496789, 0.9953489223021379, 0.002984554489661583, 0.06149316341746721, 0.7931041333073335, 0.14506079575402522, 0.13643268895836247, 0.800800565625171, 0.06327313111112462, 0.9952984658251735, 0.004629295189884528, 0.9742628878855674, 0.9857276586592683, 0.01369066192582317, 0.9961459270786451, 0.0030095043114158463, 0.0030095043114158463, 0.9939210912102803, 0.00451782314186491, 0.23574732676601004, 0.027079084831230883, 0.7375068398152881, 0.3748079106444696, 0.29708765741104454, 0.32812270733701976, 0.9442546076147404, 0.9968609736316284, 0.002504675813144795, 0.9864908163566172, 0.00808599029800506, 0.994815448959914, 0.006065947859511671, 0.9926131947286683, 0.9930276920817063, 0.9972649253193926, 0.0016989181010551833, 0.0016989181010551833, 0.9950213261419839, 0.9953940576669333, 0.997899362713269, 0.021574206505678924, 0.6661036258628368, 0.31282599433234437, 0.20654198661060855, 0.6559192801627632, 0.13725473870609128, 0.5108127620075783, 0.2671155560641348, 0.22247432614656706, 0.900325819278189, 0.09911079786688667, 0.9873024190385764, 0.9770466162582581, 0.021087337041545137, 0.9547714526737766, 0.04427367623285657, 0.9517300469039045, 0.004614448712261355, 0.04383726276648287, 0.9978910317422607, 0.3145666958753895, 0.4192395859663292, 0.265792417246627, 0.055568022403103316, 0.9446563808527564, 0.1757968758076279, 0.002917790469836148, 0.8206285696414165, 0.6835991184100815, 0.004705205338122488, 0.31121572450724455, 0.9902952663207611, 0.007263779459565485, 0.990922997233722, 0.995498522835957, 0.9773922024143287, 0.17803027885555847, 0.5026316708251309, 0.31959652469250854, 0.33062088603142004, 0.5661438290376736, 0.1039856012518176, 0.34832898398086504, 0.5536528483612996, 0.09774203128653275, 0.9279168870008955, 0.0697876210279225, 0.058719365035862114, 0.86023869777538, 0.07927114279841385, 0.9921992381002501, 0.0067131206908000686, 0.9927538568745883, 0.005839728569850519, 0.4261445513858556, 0.0006125700307415269, 0.5731613587638221, 0.9803114927005657, 0.004248370499244055, 0.014869296747354193, 0.9939784778089068, 0.004477380530670751, 0.31824652911956053, 0.30378077779594415, 0.37755610954638774, 0.9571541594682023, 0.042463673741395064, 0.9942607329816916, 0.3644360379437205, 0.4391454257221832, 0.1960665884137216, 0.5760408345500158, 0.17479070455122533, 0.24918712229753734, 0.3370828745607832, 0.2799787707216798, 0.38310348145221246, 0.10054324394089965, 0.8043459515271972, 0.09597309648904058, 0.9915775222957224, 0.9954985643953299, 0.0025138852636245705, 0.993333015823465, 0.08111384955638933, 0.8318145748625808, 0.08588525247147105, 0.19464838950054553, 0.8029246066897503, 0.04816494086639164, 0.9016476930188516, 0.052018136135702976, 0.10797005501886503, 0.4844320167660582, 0.40799303976155193, 0.9323519216984051, 0.05989412773223159, 0.00798588369763088, 0.9893538604588884, 0.02738484296355759, 0.9858543466880734, 0.019905121460488485, 0.959426854395545, 0.019905121460488485, 0.9722536528119409, 0.2271196098745235, 0.564679249825395, 0.20777700573685803, 0.9932026094484002, 0.9880051435350237, 0.5109359050206004, 0.3194023820192138, 0.16968251544770732, 0.6462555709381437, 0.22077961812592692, 0.1330526175460884, 0.28682727196134916, 0.5251469905762937, 0.1882303972246354, 0.5329496369342982, 0.24373805921227287, 0.2232749758828843, 0.9727403064275592, 0.9946558687522384, 0.7512694215119695, 0.0011665674247080273, 0.24847886146280979, 0.9949031842601249, 0.0030148581341215906, 0.717616100805325, 0.0023947144631990824, 0.2801815921942926, 0.10765407519337979, 0.3843439351202243, 0.5089960221862431, 0.9915635347410867, 0.138784681095869, 0.1838897024520264, 0.6765753203423613, 0.997983539703634, 0.14974887596445924, 0.6922215197768875, 0.15782357025666047, 0.244241381571041, 0.5999842634245137, 0.15574812737863483, 0.46320603957953893, 0.32401028526144515, 0.21288762425120225, 0.2920449420279439, 0.24272609420203284, 0.4661114637664535, 0.9986602711818042, 0.003467570386047931, 0.9445373246560408, 0.0030328057026659406, 0.9977930761770945, 0.9945037595670363, 0.004561943851224937, 0.5834654601145859, 0.038818070529629566, 0.3777296863075492, 0.9934424583173809, 0.005795772098898068, 0.9910770289115697, 0.12089713438946031, 0.01208971343894603, 0.8704593676041142, 0.9951123755133631, 0.1967391398767136, 0.4748631757455929, 0.32837036295969463, 0.9948020466934739, 0.0053732941769572, 0.9698795989407746, 0.024179823796307398, 0.8493079942537823, 0.0023823506150176224, 0.14770573813109258, 0.4404782369870178, 0.20242353610553376, 0.3570820513222261, 0.994579372288991, 0.007053754413397098, 0.9985463933635499, 0.9163687677765848, 0.002073232506281866, 0.08085606774499278, 0.9867205165503421, 0.011574434211734218, 0.0633036399474312, 0.052753033289526, 0.8862509592640367, 0.40384313281820217, 0.35018565363256693, 0.24569477311317195, 0.008552163407171078, 0.9892002340961212, 0.0028507211357236923, 0.9940329623381514, 0.05541268798820444, 0.9420156957994754, 0.0675973383136992, 0.9285739631513416, 0.0035577546480894313, 0.9870567457150213, 0.9155139182230991, 0.990901551822109, 0.00943715763640104, 0.9917078062817131, 0.30547065795968514, 0.5170072395007747, 0.17751321527923591, 0.2234474478496478, 0.778213525269463, 0.9959619473762586, 0.9958767385109785, 0.9516991788231323, 0.5645070307928708, 0.005297771926106191, 0.43029680866484726, 0.9977780315470002, 0.0018933169479070212, 0.08126470760997603, 0.9062781522590805, 0.012366368549344179, 0.9729895716236492, 0.025981029949897174, 0.990442599773032, 0.0068306386191243585, 0.9928811209427041, 0.004554500554783046, 0.9975967583779884, 0.9808170387424244, 0.018547152011814477, 0.14800485099455216, 0.6328714216735375, 0.21899360305528756, 0.9975737948370671, 0.24960114413798803, 0.10697191891628059, 0.6434523001479302, 0.34718135642720244, 0.6525039677532528, 0.21358467512981638, 0.3233661112016304, 0.4633102685704032, 0.1762675530313892, 0.7988295488443807, 0.02437742754689425, 0.9974443855975833, 0.0027402318285647894, 0.23609427952543674, 0.1886040508852627, 0.5766670620592564, 0.12261525649490487, 0.1099309196161216, 0.7652883250199235, 0.9419216347949425, 0.9918227777272429, 0.008030953665807635, 0.9900516039978874, 0.9956934575950749, 0.002758153622147022, 0.20847931246366116, 0.42914664627135174, 0.36243326628298017, 0.05870466737477189, 0.9392746779963502, 0.05745881214763303, 0.7772060379969309, 0.16481606642347368, 0.042213445300558164, 0.9435946596595355, 0.014898863047255824, 0.9883986676427456, 0.9581917601248354, 0.8937136033470158, 0.08969753318263844, 0.01793950663652769, 0.3172406539056715, 0.00634481307811343, 0.6770821956215332, 0.9512830740089856, 0.14515933357430053, 0.5599002866437306, 0.2951573116010777, 0.14217419944374377, 0.008885887465233985, 0.8530451966624626, 0.9229299160960778, 0.0017202794335434814, 0.07569229507591319, 0.9257180164260478, 0.07328600963372878, 0.9875449599063487, 0.10731101731765409, 0.7046081891800684, 0.18762555229124425, 0.9890546238200004, 0.009073895631376151, 0.48490940677701255, 0.34156277874816443, 0.17421073454223646, 0.2596673438224084, 0.42779898470833316, 0.31231222996722546, 0.9928032424576596, 0.995833755514411, 0.004979168777572055, 0.9975300003441974, 0.9268879063413268, 0.6398552210269396, 0.22952641660500664, 0.13046764733337218, 0.9671861939279519, 0.9901453841644972, 0.989031388743919, 0.9528574165324565, 0.9825744754015452, 0.9692757941974124, 0.17539002453740885, 0.24711309299085096, 0.5774008367932566, 0.2850965574489641, 0.7143078582237783, 0.2263188885727533, 0.7729003553144972, 0.27904265283958035, 0.46693510044298514, 0.2538784857498386, 0.007780393120500435, 0.9881099263035553, 0.007780393120500435, 0.4103349476372828, 0.00724120495830499, 0.5841238666366025, 0.0883595993835749, 0.7441535010585449, 0.1670548675845713, 0.1303268548389346, 0.7141911645173616, 0.15534961096801006, 0.9841238377063273, 0.9957066069009183], \"Term\": [\"apartment\", \"appointment\", \"ask\", \"ask\", \"ask\", \"atmosphere\", \"atmosphere\", \"atmosphere\", \"avec\", \"bacon\", \"bacon\", \"bad\", \"bad\", \"bad\", \"bar\", \"bar\", \"bar\", \"barista\", \"bartender\", \"bartender\", \"bartender\", \"bbq\", \"bbq\", \"bean\", \"bean\", \"bed\", \"bed\", \"beef\", \"beef\", \"beer\", \"beer\", \"beer\", \"belle\", \"bike\", \"bon\", \"bowling\", \"bread\", \"bread\", \"broth\", \"burger\", \"burger\", \"busy\", \"busy\", \"busy\", \"butter\", \"butter\", \"butter\", \"buy\", \"buy\", \"buy\", \"cake\", \"cake\", \"cake\", \"call\", \"call\", \"call\", \"car\", \"car\", \"care\", \"care\", \"care\", \"charge\", \"charge\", \"charge\", \"cheese\", \"cheese\", \"cheesetart\", \"chicken\", \"chicken\", \"chocolate\", \"chocolate\", \"chocolate\", \"class\", \"class\", \"coffee\", \"coffee\", \"coffee\", \"come\", \"come\", \"come\", \"comme\", \"company\", \"company\", \"contact\", \"contact\", \"cookie\", \"cookie\", \"corn\", \"crab\", \"cream\", \"cream\", \"cream\", \"creamy\", \"crispy\", \"crust\", \"customer\", \"customer\", \"customer\", \"day\", \"day\", \"day\", \"definitely\", \"definitely\", \"definitely\", \"delicious\", \"delicious\", \"des\", \"desk\", \"desk\", \"dessert\", \"dessert\", \"dish\", \"dish\", \"dish\", \"doctor\", \"don\", \"don\", \"don\", \"doughnut\", \"doughnut\", \"drink\", \"drink\", \"drink\", \"eat\", \"eat\", \"eat\", \"egg\", \"egg\", \"email\", \"est\", \"ethiopian\", \"experience\", \"experience\", \"experience\", \"feel\", \"feel\", \"feel\", \"find\", \"find\", \"find\", \"fish\", \"fish\", \"fix\", \"fix\", \"fix\", \"flavor\", \"flavor\", \"flavorful\", \"flavorful\", \"food\", \"food\", \"food\", \"fresh\", \"fresh\", \"fresh\", \"fried\", \"fried\", \"friendly\", \"friendly\", \"friendly\", \"fry\", \"fry\", \"garlic\", \"get\", \"get\", \"get\", \"good\", \"good\", \"good\", \"great\", \"great\", \"great\", \"guy\", \"guy\", \"guy\", \"gym\", \"hair\", \"hair\", \"haircut\", \"help\", \"help\", \"help\", \"hostess\", \"hostess\", \"hotel\", \"hotel\", \"hotel\", \"hour\", \"hour\", \"hour\", \"ice\", \"ice\", \"ice\", \"insurance\", \"ipa\", \"ipa\", \"job\", \"job\", \"job\", \"karaoke\", \"know\", \"know\", \"know\", \"lamb\", \"les\", \"like\", \"like\", \"like\", \"little\", \"little\", \"little\", \"look\", \"look\", \"look\", \"love\", \"love\", \"love\", \"mais\", \"massage\", \"meal\", \"meal\", \"meal\", \"meat\", \"meat\", \"menu\", \"menu\", \"menu\", \"minute\", \"minute\", \"minute\", \"mushroom\", \"music\", \"music\", \"music\", \"nail\", \"need\", \"need\", \"need\", \"new\", \"new\", \"new\", \"nice\", \"nice\", \"nice\", \"night\", \"night\", \"night\", \"noodle\", \"noodle\", \"nous\", \"office\", \"office\", \"onion\", \"onion\", \"order\", \"order\", \"order\", \"pas\", \"patient\", \"patient\", \"patron\", \"patron\", \"patron\", \"pedicure\", \"people\", \"people\", \"people\", \"pepper\", \"phone\", \"phone\", \"phone\", \"pizza\", \"pizza\", \"pizza\", \"place\", \"place\", \"place\", \"pool\", \"pool\", \"pork\", \"portion\", \"portion\", \"portion\", \"potato\", \"potato\", \"pour\", \"pour\", \"pour\", \"price\", \"price\", \"price\", \"professional\", \"professional\", \"professional\", \"property\", \"pub\", \"pub\", \"purchase\", \"purchase\", \"purchase\", \"que\", \"qui\", \"quote\", \"quote\", \"raman\", \"recommend\", \"recommend\", \"recommend\", \"refill\", \"refill\", \"rent\", \"repair\", \"res\", \"restaurant\", \"restaurant\", \"restaurant\", \"rice\", \"rice\", \"room\", \"room\", \"room\", \"salad\", \"salad\", \"sale\", \"sale\", \"salmon\", \"salmon\", \"salon\", \"sauce\", \"sauce\", \"say\", \"say\", \"say\", \"schedule\", \"seat\", \"seat\", \"seat\", \"server\", \"server\", \"service\", \"service\", \"service\", \"shop\", \"shop\", \"shop\", \"shrimp\", \"shrimp\", \"sit\", \"sit\", \"sit\", \"slow\", \"slow\", \"slow\", \"sont\", \"soup\", \"soup\", \"spa\", \"spicy\", \"spicy\", \"staff\", \"staff\", \"staff\", \"starbucks\", \"starbucks\", \"stay\", \"stay\", \"stay\", \"store\", \"store\", \"store\", \"stylist\", \"sur\", \"sweet\", \"sweet\", \"sweet\", \"table\", \"table\", \"table\", \"tait\", \"take\", \"take\", \"take\", \"tap\", \"tap\", \"tap\", \"taste\", \"taste\", \"taste\", \"tasty\", \"tasty\", \"tech\", \"tell\", \"tell\", \"tell\", \"thai\", \"thai\", \"think\", \"think\", \"think\", \"time\", \"time\", \"time\", \"tire\", \"tomato\", \"tomato\", \"topping\", \"tout\", \"try\", \"try\", \"try\", \"une\", \"vehicle\", \"vet\", \"victor\", \"vinny\", \"vous\", \"wait\", \"wait\", \"wait\", \"waiter\", \"waiter\", \"waitress\", \"waitress\", \"want\", \"want\", \"want\", \"wedding\", \"wedding\", \"wedding\", \"wine\", \"wine\", \"wine\", \"work\", \"work\", \"work\", \"year\", \"year\", \"year\", \"yuk\", \"yum\"]}, \"R\": 30, \"lambda.step\": 0.01, \"plot.opts\": {\"xlab\": \"PC1\", \"ylab\": \"PC2\"}, \"topic.order\": [2, 1, 3]};\n",
              "\n",
              "function LDAvis_load_lib(url, callback){\n",
              "  var s = document.createElement('script');\n",
              "  s.src = url;\n",
              "  s.async = true;\n",
              "  s.onreadystatechange = s.onload = callback;\n",
              "  s.onerror = function(){console.warn(\"failed to load library \" + url);};\n",
              "  document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
              "}\n",
              "\n",
              "if(typeof(LDAvis) !== \"undefined\"){\n",
              "   // already loaded: just create the visualization\n",
              "   !function(LDAvis){\n",
              "       new LDAvis(\"#\" + \"ldavis_el1601406509692832807173381390\", ldavis_el1601406509692832807173381390_data);\n",
              "   }(LDAvis);\n",
              "}else if(typeof define === \"function\" && define.amd){\n",
              "   // require.js is available: use it to load d3/LDAvis\n",
              "   require.config({paths: {d3: \"https://cdnjs.cloudflare.com/ajax/libs/d3/3.5.5/d3.min\"}});\n",
              "   require([\"d3\"], function(d3){\n",
              "      window.d3 = d3;\n",
              "      LDAvis_load_lib(\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.js\", function(){\n",
              "        new LDAvis(\"#\" + \"ldavis_el1601406509692832807173381390\", ldavis_el1601406509692832807173381390_data);\n",
              "      });\n",
              "    });\n",
              "}else{\n",
              "    // require.js not available: dynamically load d3 & LDAvis\n",
              "    LDAvis_load_lib(\"https://cdnjs.cloudflare.com/ajax/libs/d3/3.5.5/d3.min.js\", function(){\n",
              "         LDAvis_load_lib(\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.js\", function(){\n",
              "                 new LDAvis(\"#\" + \"ldavis_el1601406509692832807173381390\", ldavis_el1601406509692832807173381390_data);\n",
              "            })\n",
              "         });\n",
              "}\n",
              "</script>"
            ],
            "text/plain": [
              "PreparedData(topic_coordinates=              x         y  topics  cluster       Freq\n",
              "topic                                                \n",
              "1     -0.124606 -0.049957       1        1  39.802929\n",
              "0      0.136067 -0.038314       2        1  38.182724\n",
              "2     -0.011461  0.088270       3        1  22.014347, topic_info=         Term         Freq        Total Category  logprob  loglift\n",
              "133      food  4897.000000  4897.000000  Default  30.0000  30.0000\n",
              "571     drink  1370.000000  1370.000000  Default  29.0000  29.0000\n",
              "352     order  3348.000000  3348.000000  Default  28.0000  28.0000\n",
              "43    service  3680.000000  3680.000000  Default  27.0000  27.0000\n",
              "1098  chicken  1387.000000  1387.000000  Default  26.0000  26.0000\n",
              "...       ...          ...          ...      ...      ...      ...\n",
              "185       don   484.879707  1824.732267   Topic3  -5.3782   0.1882\n",
              "71        get   538.330399  2743.965733   Topic3  -5.2736  -0.1152\n",
              "634      love   490.943887  2199.082087   Topic3  -5.3658   0.0140\n",
              "284      want   454.365984  1788.257082   Topic3  -5.4432   0.1434\n",
              "144     price   435.096988  1770.489435   Topic3  -5.4866   0.1100\n",
              "\n",
              "[264 rows x 6 columns], token_table=       Topic      Freq         Term\n",
              "term                               \n",
              "1185       2  0.996803    apartment\n",
              "493        2  0.997734  appointment\n",
              "382        1  0.172638          ask\n",
              "382        2  0.474079          ask\n",
              "382        3  0.353368          ask\n",
              "...      ...       ...          ...\n",
              "109        1  0.130327         year\n",
              "109        2  0.714191         year\n",
              "109        3  0.155350         year\n",
              "10611      3  0.984124          yuk\n",
              "380        1  0.995707          yum\n",
              "\n",
              "[440 rows x 3 columns], R=30, lambda_step=0.01, plot_opts={'xlab': 'PC1', 'ylab': 'PC2'}, topic_order=[2, 1, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 141
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iE5VuiXhaGHc"
      },
      "source": [
        "## Note about  pyLDAvis\n",
        "\n",
        "**pyLDAvis** is the Topic modeling package that we used in class to visualize the topics that LDA generates for us.\n",
        "\n",
        "You are welcomed to use pyLDAvis if you'd like for your visualization. However, **you MUST comment out the code that imports the package and the cell that generates the visualization before you submit your notebook to CodeGrade.** \n",
        "\n",
        "Although you should leave the print out of the visualization for graders to see (i.e. comment out the cell after you run it to create the viz). "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HDSXYVFTaGHd"
      },
      "source": [
        "from gensim import corpora\n",
        "# Due to limited computationalresources on CodeGrader, use the non-multicore version of LDA \n",
        "from gensim.models.ldamodel import LdaModel\n",
        "import gensim\n",
        "import re"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6525gNTnaGHd"
      },
      "source": [
        "### 1. Estimate a LDA topic model of the review tex"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "9514841e71735eaa255bccc53b257896",
          "grade": false,
          "grade_id": "cell-66331a185ff52f15",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "EMW42HTZaGHd"
      },
      "source": [
        "# Remember to read the LDA docs for more information on the various class attirbutes and methods available to you\n",
        "# in the LDA model: https://radimrehurek.com/gensim/models/ldamodel.html\n",
        "\n",
        "# don't change this value \n",
        "num_topics = 5\n",
        "\n",
        "# use tokenize function you created earlier to create tokens \n",
        "\n",
        "# create a id2word object (hint: use corpora.Dictionary)\n",
        "\n",
        "# create a corpus object (hint: id2word.doc2bow)\n",
        "\n",
        "# instantiate an lda model\n",
        "\n",
        "# YOUR CODE HERE\n",
        "raise NotImplementedError()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y6CTcZAfaGHe"
      },
      "source": [
        "#### Testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "6479db0fa59c99d3ae3201c1f10ebca1",
          "grade": true,
          "grade_id": "cell-5a3c181311134fa9",
          "locked": true,
          "points": 1,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "9WQe8SOWaGHe"
      },
      "source": [
        "# Visible Testing\n",
        "assert lda.get_topics().shape[0] == 5, 'Did your model complete its training? Did you set num_topics to 5?'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "67Mr3l_UaGHe"
      },
      "source": [
        "#### 2. Create 1-2 visualizations of the results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "189591ed7b9e6e6146d59761fb418268",
          "grade": false,
          "grade_id": "cell-9b043e992fbd218c",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "02idK5rGaGHf"
      },
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Use pyLDAvis (or a ploting tool of your choice) to visualize your results \n",
        "\n",
        "# YOUR CODE HERE\n",
        "raise NotImplementedError()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "f44a26c754500ff0bf585296075bf754",
          "grade": false,
          "grade_id": "cell-bf9e63d9645bba84",
          "locked": true,
          "points": 0,
          "schema_version": 3,
          "solution": false,
          "task": true
        },
        "id": "sAaxKB6JaGHf"
      },
      "source": [
        "#### 3. In markdown, write 1-2 paragraphs of analysis on the results of your topic model"
      ]
    }
  ]
}